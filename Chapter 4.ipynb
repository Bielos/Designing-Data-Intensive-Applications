{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Encoding and Evolution\n",
    "For a data-intensive application evolution means allowing changes to the data structure and source code without affecting current processes. In essence, the application should allow upgrades to be implemented without going into downtimes. To achieve this, the application must support two types of compatibility:\n",
    "* Backward compatibility\n",
    "    - Newer code can read data that was written by older code.\n",
    "* Forward compatibility\n",
    "    - Older code can read data that was written by newer code.\n",
    "    \n",
    "The applications can be served by the use of schemes for encoding and decoding instances of the abstractions of the data, by managing these schemes it is possible to achieve the desired compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! Definition !!\n",
    "* **Encoding or serialization:** The translation from the in-memory representation to a byte\n",
    "* **Decoding or deserialization:** The translation from the byte representation to a in-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for achieving this compatibility consists of the following:\n",
    "* The Format of Encoding Data\n",
    "* The mode of Dataflow\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formats for Enconding Data\n",
    "\n",
    "The most used formats for encoding data are:\n",
    "* Lenguage-Specific Formats\n",
    "* JSON, XML, Binary variants\n",
    "* Apache Thrift and Protocol Buffers\n",
    "* Apache Avro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lenguage-Specific Formats\n",
    "Many programming languages come with built-in support for encoding in-memory\n",
    "objects into byte sequences. For example, Java has java.io.Serializable, Ruby\n",
    "has Marshal, Python has pickle, and so on. Many third-party libraries also\n",
    "exist, such as Kryo for Java.\n",
    "\n",
    "* Pros\n",
    "    - Easy to save and restore objects with few lines of code\n",
    "* Cons\n",
    "    - The encoding is often tied to a particular programming language, and readingthe data in another language is very difficult. If you store or transmit data in such an encoding, you are committing yourself to your current programming language for potentially a very long time.\n",
    "    - In order to restore data in the same object types, the decoding process needs tobe able to instantiate arbitrary classes (Insecure).\n",
    "    - Versioning data is often an afterthought in these libraries (backward and forward compatibility is usually problematic)\n",
    "    - Efficiency (CPU time taken to encode or decode, and the size of the encoded structure) is also often an afterthought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON, XML, Binary variants\n",
    "Moving to standardized encodings that can be written and read by many programming\n",
    "languages, JSON and XML are the obvious contenders. They are widely known,\n",
    "widely supported, and almost as widely disliked. XML is often criticized for being too\n",
    "verbose and unnecessarily complicated. JSON’s popularity is mainly due to its\n",
    "built-in support in web browsers (by virtue of being a subset of JavaScript) and simplicity\n",
    "relative to XML. CSV is another popular language-independent format, albeit\n",
    "less powerful.\n",
    "\n",
    "* Pros\n",
    "    - JSON, XML, and CSV are textual formats, and thus somewhat human-readable\n",
    "* Cons\n",
    "    - There is a lot of ambiguity around the encoding of numbers. In XML and CSV,\n",
    "you cannot distinguish between a number and a string that happens to consist of\n",
    "digits (except by referring to an external schema). JSON distinguishes strings and\n",
    "numbers, but it doesn’t distinguish integers and floating-point numbers, and it\n",
    "doesn’t specify a precision.\n",
    "    - JSON and XML have good support for Unicode character strings (i.e., humanreadable\n",
    "text), but they don’t support binary strings (sequences of bytes without\n",
    "a character encoding).\n",
    "\n",
    "**Binary variants**\n",
    "\n",
    "JSON is less verbose than XML, but both still use a lot of space compared to binary\n",
    "formats. This observation led to the development of a profusion of binary encodings\n",
    "for JSON (MessagePack, BSON, BJSON, UBJSON, BISON, and Smile, to name a few)\n",
    "and for XML (WBXML and Fast Infoset, for example). These formats have been\n",
    "adopted in various niches, but none of them are as widely adopted as the textual versions\n",
    "of JSON and XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apache Thrift and Protocol Buffers\n",
    "Apache Thrift and Protocol Buffers (protobuf) are binary encoding libraries\n",
    "that are based on the same principle. Both Thrift and Protocol Buffers require a schema for any data that is encoded.\n",
    "\n",
    "Thrift and Protocol Buffers each come with a code generation tool that takes a\n",
    "schema definition and produces classes that implement the\n",
    "schema in various programming languages. Your application code can call this\n",
    "generated code to encode or decode records of the schema.\n",
    "\n",
    "**Apache Thift**\n",
    "\n",
    "Thrift has two different binary encoding formats:\n",
    "* BinaryProtocol\n",
    "\n",
    "![](images/image_17.png)\n",
    "    \n",
    "* CompactProtocol\n",
    "\n",
    "![](images/image_18.png)\n",
    "\n",
    "**Protocol Buffers**\n",
    "\n",
    "![](images/image_19.png)\n",
    "\n",
    "**Forward and backward compatibility**\n",
    "\n",
    "How do Thrift and Protocol Buffers handle schema changes while\n",
    "keeping backward and forward compatibility?\n",
    "\n",
    "* If a field value is not set, it is simply omitted from the encoded record.\n",
    "    - You can change the\n",
    "name of a field in the schema, since the encoded data never refers to field names, but\n",
    "you cannot change a field’s tag, since that would make all existing encoded data\n",
    "invalid.\n",
    "* You can add new fields to the schema, provided that you give each field a new tag number\n",
    "    - The datatype annotation allows the\n",
    "parser to determine how many bytes it needs to skip. This maintains forward compatibility:\n",
    "old code can read records that were written by new code.\n",
    "* As long as each field has a unique tag number,\n",
    "new code can always read old data, because the tag numbers still have the same\n",
    "meaning.\n",
    "* Removing a field is just like adding a field, with backward and forward compatibility\n",
    "concerns reversed.\n",
    "    - You can only remove a field that is optional (a\n",
    "required field can never be removed), and you can never use the same tag number\n",
    "again (because you may still have data written somewhere that includes the old tag\n",
    "number, and that field must be ignored by new code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apache Avro\n",
    "Avro also uses a schema to specify the structure of the data being encoded. It has two\n",
    "schema languages:\n",
    "* Avro IDL\n",
    "    - Intended for human editing\n",
    "* JSON    \n",
    "    - More easily machine-readable\n",
    "    \n",
    "To parse the binary data, you go through the fields in the order that they appear in\n",
    "the schema and use the schema to tell you the datatype of each field. This means that\n",
    "the binary data can only be decoded correctly if the code reading the data is using the\n",
    "exact same schema as the code that wrote the data. Any mismatch in the schema\n",
    "between the reader and the writer would mean incorrectly decoded data.\n",
    "\n",
    "![](images/image_20.png)\n",
    "\n",
    "With Avro, when an application wants to encode some data (to write it to a file or\n",
    "database, to send it over the network, etc.), it encodes the data using whatever version\n",
    "of the schema it knows about—for example, that schema may be compiled into the\n",
    "application. This is known as the writer’s schema.\n",
    "\n",
    "When an application wants to decode some data (read it from a file or database,\n",
    "receive it from the network, etc.), it is expecting the data to be in some schema, which\n",
    "is known as the reader’s schema. That is the schema the application code is relying on\n",
    "—code may have been generated from that schema during the application’s build\n",
    "process.\n",
    "\n",
    "The key idea with Avro is that the writer’s schema and the reader’s schema don’t have\n",
    "to be the same—they only need to be compatible.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "* Large file with lots of records\n",
    "    - In this case, the writer of that\n",
    "file can just include the writer’s schema once at the beginning of the file. Avro\n",
    "specifies a file format (object container files) to do this.\n",
    "* Database with individually written records\n",
    "    - The simplest solution is to include a version number at the beginning\n",
    "of every encoded record, and to keep a list of schema versions in your database.\n",
    "* Sending records over a network connection\n",
    "    - When two processes are communicating over a bidirectional network connection,\n",
    "they can negotiate the schema version on connection setup and then use\n",
    "that schema for the lifetime of the connection. The Avro RPC protocol works like this.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modes of Dataflow\n",
    "These are the ways in which information is shared between processes that do not share memory and determine who encodes and who decodes. Some examples are:\n",
    "* Via databases\n",
    "* Via service calls\n",
    "* Via asynchronous message passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataflow through Databases\n",
    "In a database, the process that writes to the database encodes the data, and the process\n",
    "that reads from the database decodes it.\n",
    "\n",
    "**Complications**\n",
    "* Updating records\n",
    "    - If a field is updated for a newer version it may delete fields ignored in the read process (written by an old-version)\n",
    "* Different values written at different times\n",
    "* Archival storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataflow Through Services: REST and RPC\n",
    "\n",
    "The most common arrangement is\n",
    "to have two roles: _clients_ and _servers_. The servers expose an API over the network,\n",
    "and the clients can connect to the servers to make requests to that API. The API\n",
    "exposed by the server is known as a service.\n",
    "\n",
    "* Thrift, gRPC (Protocol Buffers), and Avro RPC can be evolved according to the\n",
    "compatibility rules of the respective encoding format.\n",
    "* In SOAP, requests and responses are specified with XML schemas. These can be\n",
    "evolved, but there are some subtle pitfalls.\n",
    "* RESTful APIs most commonly use JSON (without a formally specified schema)\n",
    "for responses, and JSON or URI-encoded/form-encoded request parameters for\n",
    "requests. Adding optional request parameters and adding new fields to response\n",
    "objects are usually considered changes that maintain compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message-Passing Dataflow\n",
    "They are similar to RPC in that a\n",
    "client’s request (usually called a message) is delivered to another process with low\n",
    "latency. They are similar to databases in that the message is not sent via a direct network\n",
    "connection, but goes via an intermediary called a message broker (also called a\n",
    "message queue or message-oriented middleware), which stores the message temporarily.\n",
    "\n",
    "The actor model is a programming model for concurrency in a single process. Rather\n",
    "than dealing directly with threads (and the associated problems of race conditions,\n",
    "locking, and deadlock), logic is encapsulated in actors. Each actor typically represents\n",
    "one client or entity, it may have some local state (which is not shared with any other\n",
    "actor), and it communicates with other actors by sending and receiving asynchronous\n",
    "messages. Message delivery is not guaranteed: in certain error scenarios, messages\n",
    "will be lost. Since each actor processes only one message at a time, it doesn’t\n",
    "need to worry about threads, and each actor can be scheduled independently by the\n",
    "framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
